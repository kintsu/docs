---
author: joshua-auchincloss
components:
  - compiler
created: 2025-10-31
kind: AD
number: 2
status: draft
title: Parallel Compilation Architecture
updates:
  - author: joshua-auchincloss
    date: 2025-10-31
    description: Created specification
  - author: joshua-auchincloss
    date: 2025-12-24
    description: Updated specification
version_after: 0.1.0
version_before: null
---

# AD-0002: Parallel Compilation Architecture

## Overview

This architecture document specifies the design of the parallel compilation system for multi-schema workspaces. The system consists of three major components: `DependencyLoader` for parallel dependency resolution, `SchemaCompiler` for topologically ordered schema compilation, and `SchemaDependencyGraph` for dependency analysis. The architecture enables concurrent compilation of independent schemas while maintaining correctness through careful synchronization and ordering.

## Motivation

Sequential compilation of multi-schema workspaces becomes a bottleneck as projects grow. A workspace with 100 schemas, each taking 5 seconds to compile, requires 500 seconds sequentially but could complete in ~50 seconds with optimal parallelization (assuming 10 independent groups). The parallel compilation architecture achieves this throughput improvement while preserving deterministic compilation semantics.

## Architecture

### System Components

The parallel compilation system consists of four primary components:

```rust
pub struct CompileCtx {
    pub root: Arc<SchemaCtx>,
    pub root_fs: Arc<dyn FileSystem>,
    type_registry: TypeRegistry,
    pub(super) state: Arc<RwLock<SharedCompilationState>>,
    pub(super) resolver: Arc<dyn PackageResolver>,
    pub(super) cache: SchemaCache,
    pub(super) root_path: PathBuf,
    pub(super) progress: CompilationProgress,
}
```

### System Architecture Diagram

![Parallel Compilation Architecture](../../../../diagrams/parallel_compilation_architecture.png)

_Figure 1: Worker pool architecture for parallel dependency loading. Task Scheduler seeds the task queue with initial imports. Workers pull tasks, load schemas, discover transitive dependencies, and enqueue new tasks. Result Collector aggregates outcomes and updates Shared State._

### Component 1: DependencyLoader

**Purpose**: Load all transitive schema dependencies using a worker pool pattern.

**Architecture**:

```rust
pub struct DependencyLoader;

impl DependencyLoader {
    pub async fn load_dependencies_parallel(
        root: &SchemaCtx,
        state: Arc<RwLock<SharedCompilationState>>,
        resolver: Arc<PackageResolver>,
        cache: SchemaCache,
        type_registry: TypeRegistry,
        root_path: PathBuf,
        max_concurrent_tasks: usize,
        progress: &CompilationProgress,
    ) -> Result<()>
}
```

**Worker Pool Design**:

1. **Task Channel**: Unbounded `tokio::sync::mpsc::UnboundedSender/Receiver<CompilationTask>`
   - Producer: Workers enqueue discovered dependencies
   - Consumer: Workers dequeue tasks for processing

2. **Result Channel**: Unbounded `tokio::sync::mpsc::UnboundedSender/Receiver<Result<DependencyTaskResult>>`
   - Producer: Workers send loaded dependencies or errors
   - Consumer: Result collector aggregates outcomes

3. **Completion Channel**: `tokio::sync::mpsc::UnboundedSender/Receiver<()>`
   - Signals task completion for coordinator

4. **Worker Tasks**: `max_concurrent_tasks` concurrent tokio tasks
   - Each worker loops receiving tasks until channel closes
   - Process: Resolve -> Load -> Cache -> Discover children -> Enqueue

5. **Coordinator Task**: Manages worker lifecycle and result aggregation
   - Updates shared state with loaded dependencies
   - Tracks errors in `Vec<Error>` (returns first via `take_first_error`)
   - Updates progress with loaded count

**Concurrency Control**:

```rust
pub struct SharedCompilationState {
    pub dependencies: BTreeMap<String, Arc<SchemaCtx>>,
    pub processing_set: HashSet<String>,
    pub loaded_versions: BTreeMap<String, Version>,
    pub lockfile: Option<Lockfile>,
    pub lockfile_invalidated: bool,
    pub resolved_metadata: BTreeMap<String, ResolvedMetadata>,
}

pub struct ResolvedMetadata {
    pub version: Version,
    pub source: LockedSource,
    pub checksum: String,
    pub provides: BTreeSet<String>,
    pub dependencies: Vec<String>,
}
```

Note: Uses `BTreeMap` for deterministic iteration order.

**Circular Dependency Detection**:

Note: Circular dependency detection via `processing_set` is currently deferred (TODO in loader). Detection occurs during topological grouping in `SchemaDependencyGraph::topological_groups`.

### Component 2: SchemaDependencyGraph

**Purpose**: Model schema import relationships for topological sorting.

**Architecture**:

```rust
pub struct SchemaDependencyGraph {
    pub(crate) nodes: BTreeMap<CacheKey, SchemaNode>,
}

pub struct SchemaNode {
    pub id: CacheKey,
    pub imports: Vec<Import>,
    pub depends_on: Vec<CacheKey>,
}

pub struct Import {
    pub name: String,
    pub resolved_id: Option<CacheKey>,
}
```

Note: Uses `BTreeMap` for deterministic iteration order.

**Graph Construction**:

```rust
async fn build_graph(ctx: &CompileCtx) -> Result<SchemaDependencyGraph> {
    let mut graph = SchemaDependencyGraph::new();

    // Add root schema
    let root_key = build_cache_key_for_schema(&ctx.root)?;
    let root_imports = extract_imports(&ctx.root).await;
    graph.add_schema(root_key, root_imports);

    // Add dependency schemas
    let state = ctx.state.read().await;
    for schema in state.dependencies.values() {
        let dep_key = build_cache_key_for_schema(schema)?;
        let dep_imports = extract_imports(schema).await;
        graph.add_schema(dep_key, dep_imports);
    }

    // Resolve import names to schema IDs
    graph.build_dependencies();

    Ok(graph)
}
```

**Dependency Resolution**:

```rust
pub fn build_dependencies(&mut self) {
    // Map package names to schema IDs
    let name_to_id: HashMap<String, CacheKey> = self
        .nodes
        .keys()
        .map(|id| (id.package_name.clone(), id.clone()))
        .collect();

    // Resolve each node's imports
    for schema_id in self.nodes.keys().cloned().collect::<Vec<_>>() {
        let imports = self.nodes[&schema_id].imports.clone();
        let mut depends_on = Vec::new();

        for import in imports {
            if let Some(dep_id) = name_to_id.get(&import.name) {
                if dep_id != &schema_id {
                    depends_on.push(dep_id.clone());
                }
            }
        }

        self.nodes.get_mut(&schema_id).unwrap().depends_on = depends_on;
    }
}
```

**Successor Function**:

```rust
pub fn successors(&self, schema_id: &CacheKey) -> Vec<CacheKey> {
    self.nodes
        .iter()
        .filter_map(|(id, node)| {
            if node.depends_on.contains(schema_id) {
                Some(id.clone())
            } else {
                None
            }
        })
        .collect()
}
```

### Component 3: SchemaCompiler

**Purpose**: Orchestrate topologically ordered schema compilation and type resolution.

**Architecture**:

```rust
pub struct SchemaCompiler;

impl SchemaCompiler {
    pub async fn compile_all(ctx: &CompileCtx) -> Result<()> {
        // 1. Build dependency graph
        let graph = Self::build_graph(ctx).await?;

        // 2. Detect circular dependencies via strongly_connected_components
        let components = strongly_connected_components(
            &graph.schema_ids(),
            |node| graph.successors(node)
        );
        for component in components {
            if component.len() > 1 {
                return Err(Error::SchemaCircularDependency { schemas: component });
            }
        }

        // 3. Compute topological sort groups (custom BFS from leaf nodes)
        let groups = graph.topological_groups()?;

        // 4. Compile each group (sequential within group)
        for (level, group) in groups.iter().enumerate() {
            for schema_id in group {
                Self::compile_schema(ctx, schema_id).await?;
            }
        }

        // 5. Resolve types for each group (sequential within group)
        for (level, group) in groups.iter().enumerate() {
            for schema_id in group {
                Self::resolve_schema_types(ctx, schema_id).await?;
            }
        }

        Ok(())
    }
}
```

Note: Within-group compilation is currently sequential (not parallel via `try_join_all`).

**Dependency Graph Visualization**:

![Schema Dependency Graph](../../../../diagrams/schema_dependency_graph.png)

_Figure 2: Topological grouping of schemas into compilation levels. Level 0 schemas have no dependencies and compile first. Level 1 schemas depend only on Level 0. Schemas within a level compile sequentially._

**Topological Grouping**:

Uses custom BFS algorithm from leaf nodes (schemas with no dependencies):

```rust
pub fn topological_groups(&self) -> Result<Vec<Vec<CacheKey>>> {
    // BFS from leaf nodes (no dependencies)
    let mut level_map: HashMap<CacheKey, usize> = HashMap::new();
    let mut queue: VecDeque<(CacheKey, usize)> = VecDeque::new();

    // Seed with leaf nodes at level 0
    for (schema_id, node) in &self.nodes {
        if node.depends_on.is_empty() {
            queue.push_back((schema_id.clone(), 0));
            level_map.insert(schema_id.clone(), 0);
        }
    }

    // Propagate levels to successors
    while let Some((current, level)) = queue.pop_front() {
        for successor in self.successors(&current) {
            let successor_level = level + 1;
            if successor_level > level_map.get(&successor).copied().unwrap_or(0) {
                level_map.insert(successor.clone(), successor_level);
                queue.push_back((successor, successor_level));
            }
        }
    }

    // Group by level
    // ...
}
```

**Schema Compilation**:

```rust
async fn compile_schema(ctx: &CompileCtx, schema_id: &CacheKey) -> Result<()> {
    let schema = ctx.get_dependency(&schema_id.package_name).await?;

    // Build namespace levels (BFS from root namespaces)
    let levels = Self::namespace_levels(&schema).await;

    // Register types depth-first
    for (depth, group) in levels.into_iter().enumerate() {
        let tasks: Vec<_> = group
            .iter()
            .map(|ns_name| Self::register_types_recursive(&schema, ns_name, depth))
            .collect();
        futures_util::future::try_join_all(tasks).await?;
    }

    Ok(())
}
```

**Type Resolution**:

```rust
async fn resolve_schema_types(ctx: &CompileCtx, schema_id: &CacheKey) -> Result<()> {
    let schema = ctx.get_dependency(&schema_id.package_name).await?;
    let resolution_levels = Self::namespace_levels(&schema).await;

    // Resolve types depth-first
    for (depth, group) in resolution_levels.into_iter().enumerate() {
        let tasks: Vec<_> = group
            .iter()
            .map(|ns_name| Self::resolve_namespace_types(&schema, ns_name))
            .collect();
        futures_util::future::try_join_all(tasks).await?;
    }

    Ok(())
}
```

### Component 4: CompileCtx

**Purpose**: Top-level compilation coordinator and context holder.

**Initialization Flow**:

```rust
pub async fn from_entry_point_with_config(
    entry_path: impl AsRef<Path>,
    max_concurrent_tasks: usize,
    show_progress: bool,
) -> Result<Self> {
    // 1. Initialize components
    let progress = CompilationProgress::new(show_progress);
    let registry = TypeRegistry::new();
    let resolver = Arc::new(PackageResolver::new());
    let cache = SchemaCache::new();

    // 2. Load root schema
    let root = Arc::new(SchemaCtx::from_path(&entry_path, registry.clone()).await?);

    // 3. Load existing lockfile
    let lockfile = Lockfiles::new_for_opt(&root_path)?;
    let state = Arc::new(RwLock::new(SharedCompilationState {
        lockfile,
        ..Default::default()
    }));

    let ctx = Self {
        root,
        type_registry: registry.clone(),
        state: state.clone(),
        resolver: resolver.clone(),
        cache: cache.clone(),
        root_path,
        progress: progress.clone(),
    };

    // 4. Load dependencies in parallel
    DependencyLoader::load_dependencies_parallel(
        &ctx.root,
        state,
        resolver,
        cache,
        registry,
        ctx.root_path.clone(),
        max_concurrent_tasks,
        &progress,
    ).await?;

    // 5. Compile all schemas in topological order
    SchemaCompiler::compile_all(&ctx).await?;

    progress.finish();
    Ok(ctx)
}
```

### Module Organization

```text
parser/src/ctx/compile/
 |--- mod.rs                    # Public API exports
 |--- context.rs                # CompileCtx
 |--- coordinator.rs            # CoordinatorState, dependency_worker, dependency_coordinator
 |--- loader.rs                 # DependencyLoader
 |--- schema_compiler.rs        # SchemaCompiler
 |--- state.rs                  # SharedCompilationState, ResolvedMetadata
 |--- resolver.rs               # PackageResolver (trait)
 |--- lockfile.rs               # LockfileManager
 |--- progress.rs               # CompilationProgress
 |--- utils.rs                  # Utilities

parser/src/ctx/graph/
 |--- mod.rs                    # Graph exports
 |--- schemas.rs                # SchemaDependencyGraph
 |--- types.rs                  # Type dependency graphs
 |--- references.rs             # Reference graphs
 |--- extract.rs                # Graph construction utilities
```

#### CoordinatorState

Manages worker lifecycle and aggregates results (from `parser/src/ctx/compile/coordinator.rs`):

```rust
pub(super) struct CoordinatorState {
    pending_tasks: Arc<AtomicUsize>,
    errors: Arc<Mutex<Vec<crate::Error>>>,
    state: Arc<RwLock<SharedCompilationState>>,
    progress: CompilationProgress,
}

impl CoordinatorState {
    pub fn increment_pending(&self);
    pub fn decrement_pending(&self) -> usize;
    pub fn pending_count(&self) -> usize;
    pub async fn record_error(&self, error: Error);
    pub async fn take_first_error(&self) -> Option<Error>;
}
```

## Design Principles

### Principle 1: Bounded Concurrency

**Rationale**: Prevent resource exhaustion through configurable worker pool size.

**Implementation**: `max_concurrent_tasks` parameter limits concurrent tokio tasks. Default to `num_cpus::get()` for CPU-bound workloads.

**Trade-off**: Lower concurrency improves memory predictability but reduces throughput. Higher concurrency maximizes CPU utilization but increases memory pressure.

### Principle 2: Work Distribution via Channels

**Rationale**: Decouple task production from consumption for flexible work-stealing.

**Implementation**: Unbounded `tokio::sync::mpsc` channels for tasks and results. Workers pull tasks as they become available. A `CoordinatorState` manages pending task count and error collection.

**Trade-off**: Unbounded channels prevent deadlocks but allow unbounded memory growth if producers overwhelm consumers. Mitigated by bounded worker pool.

### Principle 3: Fail-Fast Error Propagation

**Rationale**: Stop compilation immediately on first error to provide fast feedback.

**Implementation**: Workers break on error and send to result channel. Collector propagates first error after workers complete.

**Trade-off**: Early termination improves developer experience but may hide multiple errors that could be reported simultaneously.

### Principle 4: Dependency-Ordered Execution

**Rationale**: Ensure types are registered before dependent schemas reference them.

**Implementation**: Topological sort groups schemas into levels. Level N compiles only after levels 0..N-1 complete.

**Trade-off**: Sequential level execution reduces maximum parallelism but guarantees correctness. Alternative (full parallelism with synchronization) adds complexity.

### Principle 5: Separation of Concerns

**Rationale**: Isolate dependency loading, compilation, and resolution for maintainability.

**Implementation**: Three distinct phases with clear boundaries. Each phase completes before next begins.

**Trade-off**: Pipelined execution could start compiling schemas while loading continues, but complicates error handling and progress tracking.

## Implications

### For Implementers

1. **Thread Safety**: All shared state must use `Arc<RwLock<T>>` for concurrent access
2. **Error Handling**: Workers must propagate errors through result channel, not panic
3. **Progress Tracking**: Update progress indicators after each level completes
4. **Testing**: Test with both sequential (max_concurrent_tasks=1) and parallel execution

### For Code Generators

1. **Type Availability**: Generated code can assume all imported types are registered
2. **Determinism**: Compilation order is deterministic for reproducible builds
3. **Caching**: SchemaCache provides memoization for identical dependency versions

### For Debugging

1. **Tracing**: Instrument each phase with tracing spans for observability
2. **Circular Dependencies**: Error messages include full dependency chain
3. **Progress Visibility**: Spinners and progress bars show compilation status

### For Testing

1. **Unit Tests**: Test each component (DependencyLoader, SchemaDependencyGraph, SchemaCompiler) independently
2. **Integration Tests**: Test full compilation with synthetic multi-schema workspaces
3. **Concurrency Tests**: Verify correctness under high concurrency (max_concurrent_tasks=100)

### For Performance

1. **CPU-Bound**: Default concurrency (`num_cpus::get()`) optimal for local compilation
2. **I/O-Bound**: Increase concurrency for network-based package fetching
3. **Memory-Bound**: Reduce concurrency for large schemas or constrained environments

## References

- [RFC-0014](/specs/rfc/rfc-0014) — Parallel Compilation Design
- [SPEC-0014](/specs/spec/spec-0014) — Schema Compilation
- [AD-0001](/specs/ad/ad-0001) — Type Resolution Architecture
