---
author: joshua-auchincloss
components:
  - compiler
created: 2025-10-31
kind: RFC
number: 14
status: draft
title: Parallel Compilation Design
updates:
  - author: joshua-auchincloss
    date: 2025-10-31
    description: Created specification
version_after: 0.1.0
version_before: null
---

# RFC-0014: Parallel Compilation Design

## Abstract

This RFC specifies the design of the parallel compilation system for multi-schema workspaces. The system enables concurrent compilation of independent schemas through dependency graph analysis, topological ordering, and worker pool parallelization. The design maximizes throughput by exploiting schema independence while preserving correctness through careful dependency management.

## Motivation

### The Multi-Schema Compilation Challenge

Modern Kintsu projects consist of multiple schemas with complex import dependencies. Sequential compilation of N schemas with average time T results in O(N × T) total compilation time. For large workspaces (100+ schemas), this becomes prohibitively slow.

Sequential compilation example:

```text
Schema A (no deps)     -> 5s
Schema B (no deps)     -> 5s
Schema C (deps: A, B)  -> 5s
Schema D (deps: A)     -> 5s
Schema E (deps: C, D)  -> 5s

Sequential: 5 + 5 + 5 + 5 + 5 = 25 seconds
```

However, schemas A and B have no dependencies and can compile simultaneously. Similarly, C and D both depend only on A and B, so they can compile together once A and B finish. Optimal parallel compilation would be:

```text
Level 0: [A, B]        -> 5s (parallel)
Level 1: [C, D]        -> 5s (parallel)
Level 2: [E]           -> 5s

Parallel: 5 + 5 + 5 = 15 seconds (40% reduction)
```

### Dependency Management Requirements

Three critical requirements emerge:

1. **Circular Dependency Detection**: Schemas forming import cycles (A -> B -> C -> A) must be detected before compilation begins
2. **Compilation Ordering**: Schemas must compile after all their dependencies complete
3. **Type Availability**: A schema's types must be registered before dependent schemas reference them

### Performance Goals

The parallel compilation system must achieve:

- **Throughput**: Compile independent schemas concurrently up to CPU core count
- **Scalability**: Handle 1000+ schema workspaces with minimal overhead
- **Resource Control**: Limit concurrent tasks to prevent memory exhaustion
- **Progress Visibility**: Provide real-time feedback on compilation status

## Specification

### Design Overview

The parallel compilation system consists of three phases:

1. **Dependency Loading Phase**: Load all transitive dependencies using worker pool
2. **Schema Compilation Phase**: Compile schemas in topologically sorted groups
3. **Type Resolution Phase**: Resolve types within schemas in dependency order

### Phase 1: Dependency Loading

**Architecture**: Worker pool pattern with async channels

```rust
pub async fn load_dependencies_parallel(
    root: &SchemaCtx,
    state: Arc<RwLock<SharedCompilationState>>,
    resolver: Arc<PackageResolver>,
    cache: SchemaCache,
    type_registry: TypeRegistry,
    root_path: PathBuf,
    max_concurrent_tasks: usize,
    progress: &CompilationProgress,
) -> Result<()>
```

**Algorithm**:

1. **Initialization**: Create unbounded task and result channels
2. **Seed Queue**: Enqueue root schema's direct imports as initial tasks
3. **Spawn Workers**: Create `max_concurrent_tasks` worker tasks
4. **Work Distribution**:
   - Workers receive compilation tasks from task channel
   - Each task specifies package name and dependency chain
   - Workers resolve dependencies, load schemas, register in shared state
   - Workers discover transitive dependencies and enqueue new tasks
5. **Result Collection**: Separate collector task aggregates results and handles errors
6. **Completion**: Close channels, join all workers, propagate any errors

**Concurrency Semantics**:

- **Task Channel**: Unbounded to prevent deadlocks from circular enqueuing
- **Result Channel**: Unbounded to prevent worker blocking on send
- **Shared State**: `RwLock<SharedCompilationState>` for thread-safe dependency map
- **Processing Set**: Tracks in-flight packages to detect circular dependencies

**Example**:

```rust
// Worker processing loop
while let Ok(task) = task_rx.recv().await {
    match Self::process_dependency_task(
        task,
        state.clone(),
        resolver.clone(),
        cache.clone(),
        root_path.clone(),
        root_package.clone(),
        registry.clone(),
    )
    .await
    {
        Ok(DependencyTaskResult::Loaded(result)) => {
            // Register dependency in shared state
            state.write().await.dependencies.insert(
                result.package_name.clone(),
                result.schema.clone(),
            );

            // Enqueue transitive dependencies
            for child_dep in result.schema.get_imports() {
                task_tx.send(CompilationTask {
                    package_name: child_dep,
                    dependency_chain: /* updated chain */,
                }).await?;
            }
        }
        Err(e) => {
            result_tx.send(Err(e)).await?;
            break;
        }
    }
}
```

### Phase 2: Schema Compilation

**Architecture**: Topological sort with level-wise parallel compilation

**Algorithm**:

1. **Build Dependency Graph**: Extract import relationships between all schemas
2. **Detect Cycles**: Use strongly connected components (Tarjan's algorithm)
3. **Topological Grouping**: Group schemas into compilation levels
4. **Parallel Compilation**: Within each level, compile all schemas concurrently
5. **Progress Tracking**: Update progress bar after each level completes

**Dependency Graph**:

```rust
pub struct SchemaDependencyGraph {
    nodes: HashMap<CacheKey, SchemaNode>,
}

pub struct SchemaNode {
    id: CacheKey,
    imports: Vec<Import>,
    depends_on: Vec<CacheKey>,
}
```

**Topological Grouping**:

```rust
// Uses pathfinding::topological_sort_into_groups
let groups: Vec<Vec<CacheKey>> = topological_sort_into_groups(
    &graph.schema_ids(),
    |schema_id| graph.successors(schema_id)
)?;

// groups[0] contains schemas with no dependencies
// groups[1] contains schemas depending only on groups[0]
// groups[n] contains schemas depending only on groups[0..n]
```

**Parallel Execution**:

```rust
for (level, group) in groups.iter().enumerate() {
    let tasks: Vec<_> = group
        .iter()
        .map(|schema_id| Self::compile_schema(ctx, schema_id))
        .collect();

    // All schemas in this level compile concurrently
    futures_util::future::try_join_all(tasks).await?;
}
```

### Phase 3: Type Resolution

**Architecture**: Sequential 8-phase resolution per namespace, parallel across namespaces

**Algorithm**:

1. **Namespace Ordering**: Within each schema, compute namespace depth levels using BFS
2. **Level-wise Resolution**: Process namespaces depth-first to ensure parent types exist
3. **Parallel Execution**: All namespaces at same depth resolve concurrently
4. **TypeResolver Integration**: Each namespace executes all 8 resolution phases

**Namespace Ordering**:

```rust
// Build namespace levels by depth (BFS from root namespaces)
let levels: Vec<Vec<String>> = Self::namespace_levels(&schema).await;

// levels[0] = root namespaces (no parent)
// levels[1] = namespaces with parent in levels[0]
// levels[n] = namespaces with parent in levels[n-1]

for (depth, group) in levels.into_iter().enumerate() {
    let tasks: Vec<_> = group
        .iter()
        .map(|ns_name| Self::resolve_namespace_types(&schema, ns_name))
        .collect();

    futures_util::future::try_join_all(tasks).await?;
}
```

## Rationale

### Why Worker Pool for Dependency Loading?

**Alternatives Considered**:

1. **Recursive Spawn**: Spawn task for each dependency discovered
   - **Rejected**: Unbounded task creation for deep dependency trees
   - Memory exhaustion with 1000+ transitive dependencies

2. **Fixed Batch Size**: Process dependencies in fixed-size batches
   - **Rejected**: Poor CPU utilization when batch size < core count
   - Idle workers waiting for batch completion

3. **Worker Pool with Task Queue** (chosen):
   - Bounded concurrency through `max_concurrent_tasks`
   - Work-stealing behaviour through shared task channel
   - Efficient CPU utilization through continuous work distribution

### Why Topological Sort for Schema Compilation?

**Alternatives Considered**:

1. **Dependency-Driven Execution**: Compile each schema when dependencies ready
   - **Rejected**: Complex state tracking and notification mechanism
   - Difficult to provide progress visibility

2. **Full Parallel with Retry**: Compile all schemas, retry on missing dependencies
   - **Rejected**: Wasteful recompilation, poor error messages

3. **Topological Levels** (chosen):
   - Clear compilation order visualization
   - Simple parallel execution within levels
   - No wasted work or retries

### Why Separate Type Resolution Phase?

Type resolution requires all schemas to have registered their types in the TypeRegistry before cross-schema reference validation can occur. Attempting resolution during schema compilation would require complex synchronization to ensure type availability.

**Benefits of Separation**:

- Clean phase boundaries (registration -> resolution)
- No cross-schema synchronization within TypeResolver
- Parallel resolution safe due to read-only TypeRegistry access

### Why Configurable Concurrency?

`max_concurrent_tasks` allows tuning based on:

- **CPU Cores**: Default to `num_cpus::get()` for CPU-bound work
- **Memory**: Reduce for memory-constrained environments
- **I/O**: Increase for I/O-bound operations (network package fetching)

## Acceptance Criteria

- [x] RFC-0014.AC-1: System loads all transitive dependencies using worker pool with configurable concurrency
- [x] RFC-0014.AC-2: System detects circular schema dependencies using strongly connected components
- [x] RFC-0014.AC-3: System computes topological compilation order grouping independent schemas
- [x] RFC-0014.AC-4: System compiles all schemas in topological group concurrently
- [x] RFC-0014.AC-5: System resolves types within schemas in dependency order
- [x] RFC-0014.AC-6: System provides progress visibility through spinners and progress bars
- [x] RFC-0014.AC-7: System respects `max_concurrent_tasks` limit for resource control
- [x] RFC-0014.AC-8: System propagates first error to stop compilation on failure

## Backwards Compatibility

This RFC introduces no breaking changes to existing APIs. The parallel compilation system is an internal compiler optimization transparent to users. Schema semantics, type system rules, and generated code remain unchanged.

The `CompileCtx` API remains stable:

```rust
// Existing API preserved
pub async fn from_entry_point(entry_path: impl AsRef<Path>) -> Result<Self>

// New configuration option (backwards compatible)
pub async fn from_entry_point_with_config(
    entry_path: impl AsRef<Path>,
    max_concurrent_tasks: usize,
    show_progress: bool,
) -> Result<Self>
```

## References

- [AD-0002](/specs/ad/ad-0002) — Parallel Compilation Architecture
- [SPEC-0014](/specs/spec/spec-0014) — Schema Compilation
- [RFC-0013](/specs/rfc/rfc-0013) — Type Resolution Design
